import os
from dotenv import load_dotenv
load_dotenv()

from llm.hiaku import claude_haiku

from pydantic import BaseModel, Field
from typing import List, Optional
from enum import Enum


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ENUMS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class CoverageStatus(str, Enum):
    FULFILLED   = "FULFILLED"
    PARTIAL     = "PARTIAL"
    UNFULFILLED = "UNFULFILLED"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OUTPUT MODELS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class NoteItem(BaseModel):
    topic:       str           = Field(description="'<Entity> â€” <Dimension>' format. E.g. 'Zomato â€” FY2024 Revenue'. Never generic headings.")
    description: str           = Field(description="4â€“6 sentences. Must contain: core fact + specific number/date/name + trend/magnitude + comparison + implication. Zero vague sentences.")
    source:      Optional[str] = Field(default=None, description="Direct URL from collected_data only. Never a field path. Null if no URL available.")


class SearchQuery(BaseModel):
    type: str = Field(
        description="Entity type: person, company, product, place, event, concept, sports, statistics, route, etc."
    )
    name: str = Field(
        description="Full canonical name of the entity exactly as it appears on the web."
    )
    primary_identifier: str = Field(
        description=(
            "The single most identifying attribute that distinguishes this entity from all others "
            "with the same name. Pick the ONE fact that eliminates ambiguity on the web.\n"
            "Examples by type:\n"
            "  person  â†’ current employer or last known role  ('CEO, Hindustan Unilever')\n"
            "  company â†’ industry + country                   ('FMCG, India')\n"
            "  product â†’ parent company or category           ('Unilever, soap')\n"
            "  place   â†’ state/country                        ('Maharashtra, India')\n"
            "  event   â†’ year + organizer                     ('2024, ICC')\n"
            "Never use vague values like 'unknown', 'N/A', or research directives."
        )
    )
    secondary_identifier: Optional[str] = Field(
        default=None,
        description=(
            "A second grounding fact â€” only include if primary_identifier alone is still ambiguous. "
            "Leave null if primary is sufficient. Null is better than a weak second identifier.\n"
            "Examples:\n"
            "  person  â†’ city or alma mater  ('Mumbai' / 'IIT Bombay')\n"
            "  company â†’ founding year or HQ ('1933' / 'Mumbai')\n"
            "  product â†’ product line        ('Dove Beauty Bar')\n"
            "  place   â†’ district or region  ('Konkan coast')\n"
            "Never populate just to add detail."
        )
    )
    query: str = Field(
        description=(
            "Exactly 1 web search query string targeting a gap domain. "
            "Must incorporate name + primary_identifier to stay anchored. "
            "ZERO domain overlap with already_used_search_queries."
        )
    )


class ResearchAnalysisOutput(BaseModel):
    primary_status:   CoverageStatus = Field(
        description="Coverage of primary_research_purpose by collected_data."
    )
    secondary_status: CoverageStatus = Field(
        description="Coverage of secondary_research_purpose by collected_data."
    )

    remaining_primary_research_purpose: List[str] = Field(
        description=(
            "Ordered list of specific primary sub-questions or facts still unanswered "
            "after evaluating collected_data. Empty list [] if primary_status = FULFILLED. "
            "Each item must be a concrete answerable question â€” not a vague category. "
            "Order by importance â€” most critical gap first."
        )
    )
    remaining_secondary_research_purpose: List[str] = Field(
        description=(
            "Ordered list of specific secondary sub-questions or facts still unanswered. "
            "Empty list [] if secondary_status = FULFILLED. "
            "Only populated after primary gaps are identified. "
            "Each item must be a concrete answerable question. "
            "Order by importance â€” most critical gap first."
        )
    )

    notes: List[NoteItem] = Field(
        default=None,
        description=(
            "Populated when primary_status is FULFILLED or PARTIAL. "
            "Minimum 5 notes if FULFILLED, minimum 3 if PARTIAL. "
            "Each note covers exactly ONE distinct fact â€” never merge two facts. "
            "Cover both primary and secondary purposes across the note set."
        )
    )
    search_queries: List[SearchQuery] = Field(
        default=None,
        description=(
            "List of SearchQuery objects, each targeting one remaining gap. "
            "Populated when primary_status is UNFULFILLED or PARTIAL. "
            "PRIORITY: fill slots from remaining_primary gaps first. "
            "Use remaining_secondary gaps for slots ONLY after remaining_primary is exhausted. "
            "Each SearchQuery: type, name, primary_identifier (required), "
            "secondary_identifier (only if needed), and 1 query string anchored to name + primary_identifier."
        ),
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PROMPT BUILDERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_system_prompt(num_queries: int) -> str:
    return f"""\
You are a precision research analysis agent operating inside a multi-step research pipeline. \
Your job has four sequential stages. Complete them in strict order.

Every output feeds the next iteration of the pipeline. \
Accuracy, specificity, and zero hallucination are non-negotiable.


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
STAGE 1 â€” EXTRACT NOTES FROM COLLECTED DATA
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Before scoring anything, read all of `collected_data` and extract every relevant fact \
as a structured note. This is your evidence base for all subsequent stages.

TOPIC FORMAT
  Pattern: "<Entity> â€” <Dimension>"
  âœ… "Zomato â€” FY2024 Revenue"
  âœ… "Priya Nair â€” Current Role"
  âœ… "Blinkit â€” Unit Economics"
  âŒ "Overview" | "Background" | "Summary" | "Key Facts" | "General Info"

ONE NOTE = ONE FACT
  Never merge two distinct facts into a single note. Split them.
  âŒ WRONG: "Revenue grew 40% and the company hired a new CFO."
  âœ… RIGHT: Two separate notes â€” one for revenue growth, one for CFO hire.

DESCRIPTION DENSITY â€” each description must contain ALL five:
  1. Core fact  (what happened / what is true)
  2. Specific number, date, or named person/product/company
  3. Trend or magnitude  (direction + size of change)
  4. Comparison  (vs. competitor, prior period, or benchmark)
  5. Implication  (what this means for the research purpose)
  Length: 4â€“6 sentences. Every sentence must carry unique, non-redundant information.

  âœ… CORRECT:
    "Raised $120M Series C at a $1.4B valuation in March 2024, led by Sequoia, bringing total \
funding to $210M â€” a 3Ã— step-up from the $400M Series B valuation in 2022. The round was \
oversubscribed by 2Ã—, signaling strong investor confidence despite the broader market correction. \
Competitors Razorpay and BharatPe raised at flat valuations in the same period, making this a \
meaningful outlier. The capital is earmarked for Southeast Asia expansion and LLM infrastructure, \
directly relevant to assessing international growth readiness."

  âŒ WRONG (vague, no numbers, no names):
    "The company has been growing and has raised several rounds of funding."

  âŒ WRONG (two facts merged):
    "Revenue grew 40% and the company also hired a new CFO."

SOURCE RULE
  `source` must be a URL extracted verbatim from `collected_data`.
  âŒ Never: "web_results[1]" | "linkedin_data" | "collected_data.news[0]"
  If no direct URL exists for a note, set source = null.


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
STAGE 2 â€” SCORE COVERAGE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Using the notes you just extracted, score both purposes:

  FULFILLED    â€” Notes clearly and completely answer the purpose. No meaningful gaps.
  PARTIAL      â€” Notes partially answer but at least one significant gap remains.
  UNFULFILLED  â€” Notes contain no meaningful answer to the purpose.

Score `primary_research_purpose` first.
Score `secondary_research_purpose` independently after.


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
STAGE 3 â€” IDENTIFY REMAINING GAPS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

After scoring, list every sub-question or fact within each purpose that is still unanswered \
or only partially answered by the extracted notes.

`remaining_primary_research_purpose`
  - List every primary sub-question not yet answered by the notes.
  - Each item must be a concrete, specific, answerable question â€” not a vague category.
  - Order by criticality: most important gap first.
  - Set to [] if primary_status = FULFILLED.

  âœ… CORRECT: "What is HUL's total supply chain capex for FY2024?"
  âŒ WRONG:   "Supply chain details" | "More information needed"

`remaining_secondary_research_purpose`
  - Same rules applied to secondary purpose.
  - Set to [] if secondary_status = FULFILLED.


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
STAGE 4 â€” GENERATE SEARCH QUERIES
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Generate exactly {num_queries} SearchQuery objects only when primary_status = PARTIAL or UNFULFILLED.
Each SearchQuery targets one remaining gap and must contain:
  - `type`                 â€” entity type (person, company, product, place, event, etc.)
  - `name`                 â€” full canonical name as it appears on the web
  - `primary_identifier`   â€” the ONE fact that eliminates ambiguity for this entity on the web
                             person  â†’ current employer/role  ('CEO, Hindustan Unilever')
                             company â†’ industry + country     ('FMCG, India')
                             product â†’ parent company/category ('Unilever, soap')
                             place   â†’ state/country          ('Maharashtra, India')
                             event   â†’ year + organizer       ('2024, ICC')
  - `secondary_identifier` â€” second grounding fact ONLY if primary alone is still ambiguous.
                             Set to null if primary is sufficient. Null > weak second identifier.
  - `query`                â€” exactly 1 search string incorporating name + primary_identifier.
                             ZERO domain overlap with already_used_search_queries.

PRIORITY â€” strictly enforced:
  1. Fill slots from remaining_primary gaps first â€” up to all {num_queries} if enough primary gaps exist.
  2. Use remaining_secondary gaps for leftover slots ONLY after remaining_primary is exhausted.
  3. Never generate a secondary-gap query when a primary gap is still unresolved.
  4. If combined remaining gaps < {num_queries}, generate angle variants per gap
     (different portal, filetype, geography, time period) to reach exactly {num_queries}.

SLOT-FILL REFERENCE  (N = {num_queries})
  Primary gaps â‰¥ N   â†’ all N slots from primary
  Primary gaps < N   â†’ fill primary first, use secondary for remaining slots
  Primary gaps = 0   â†’ all N slots from secondary
  Combined gaps < N  â†’ cover each gap from multiple angles to reach N

DOMAIN FRESHNESS RULE
  Each query string must target a domain with ZERO semantic overlap with `already_used_search_queries`.
  Before writing each query: "Does any already-used query touch this domain?"
    YES â†’ different angle (portal, filetype, geography, time period, data type).
    NO  â†’ proceed.

  âœ… CORRECT SearchQuery objects:
    {{
      "type": "company",
      "name": "Hindustan Unilever",
      "primary_identifier": "FMCG, India",
      "secondary_identifier": null,
      "query": "Hindustan Unilever FMCG India supply chain vendor contracts GeM portal 2024"
    }},
    {{
      "type": "company",
      "name": "Hindustan Unilever",
      "primary_identifier": "FMCG, India",
      "secondary_identifier": "Mumbai HQ",
      "query": "Hindustan Unilever annual report 2024 logistics capex filetype:pdf"
    }}

  âŒ WRONG (primary_identifier is vague / query reuses used domain):
    {{
      "type": "person",
      "name": "Priya Nair",
      "primary_identifier": "unknown",       â† never use unknown
      "secondary_identifier": "HUL",
      "query": "Priya Nair HUL LinkedIn"     â† LinkedIn already used
    }}

Set search_queries = null when both primary_status AND secondary_status = FULFILLED.


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
OUTPUT MODE DECISION TABLE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  PRIMARY = FULFILLED   â†’  notes only           (search_queries = null)
  PRIMARY = PARTIAL     â†’  notes + queries      (both populated)
  PRIMARY = UNFULFILLED â†’  queries only         (notes = null)


â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ABSOLUTE CONSTRAINTS
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1.  Complete all 4 stages in order: Extract â†’ Score â†’ Gaps â†’ Queries.
2.  Every note must be directly traceable to `collected_data`. Zero hallucination.
3.  `source` must be a verbatim URL from `collected_data`, or null. Never a field path.
4.  Remaining gap items must be concrete answerable questions, not vague categories.
5.  Search queries derived from remaining gaps â€” primary gaps take absolute priority.
6.  Never generate a secondary-gap query while primary gaps remain unresolved.
7.  Each SearchQuery.query must have zero domain overlap with `already_used_search_queries`.
8.  SearchQuery.primary_identifier must be a known, confident fact â€” never 'unknown' or 'N/A'.
9.  SearchQuery.secondary_identifier must be null unless primary alone is genuinely ambiguous.
10. SearchQuery.query must incorporate name + primary_identifier.
11. Minimum notes: 5 if FULFILLED, 3 if PARTIAL. Produce maximum notes data supports.
12. One note = one fact. Never merge distinct facts.
13. Every description must contain at least one specific number, date, or named entity.
14. Always return exactly {num_queries} SearchQuery objects when queries are required â€” never fewer.
"""


def build_user_prompt(research: dict, num_queries: int) -> str:
    return f"""\
Execute all 4 stages in order for the research data below.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PRIMARY RESEARCH PURPOSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{research["user_intent"]["primary_research_purpose"]}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SECONDARY RESEARCH PURPOSE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{research["user_intent"]["secondary_research_purpose"]}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ALREADY USED SEARCH QUERIES
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{research.get("used_queries", [])}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COLLECTED DATA
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{research["research_data"]}

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EXECUTION CHECKLIST â€” complete in order
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

STAGE 1 â€” EXTRACT NOTES
[ ] Read all of collected_data
[ ] Extract every relevant fact as a separate note
[ ] Each topic: "<Entity> â€” <Dimension>" â€” no generic headings
[ ] Each description: 4â€“6 sentences with core fact + number + trend + comparison + implication
[ ] Each source: verbatim URL or null â€” never a field path
[ ] One note = one fact â€” no merging

STAGE 2 â€” SCORE COVERAGE
[ ] primary_status   scored: FULFILLED / PARTIAL / UNFULFILLED
[ ] secondary_status scored: FULFILLED / PARTIAL / UNFULFILLED

STAGE 3 â€” IDENTIFY GAPS
[ ] remaining_primary_research_purpose  â€” concrete answerable questions, ordered by criticality
[ ] remaining_secondary_research_purpose â€” concrete answerable questions, ordered by criticality
[ ] Both set to [] if their respective status = FULFILLED

STAGE 4 â€” GENERATE QUERIES (only if primary = PARTIAL or UNFULFILLED)
[ ] Exactly {num_queries} SearchQuery objects
[ ] Each has: type, name, primary_identifier (confident fact only), secondary_identifier (null if not needed), query
[ ] primary_identifier must be a known confident fact â€” never 'unknown' or 'N/A'
[ ] secondary_identifier = null unless primary alone is genuinely ambiguous
[ ] query incorporates name + primary_identifier
[ ] Fill all {num_queries} slots from remaining_primary first
[ ] Use remaining_secondary for leftover slots ONLY after primary is exhausted
[ ] If combined gaps < {num_queries}, generate angle variants to reach exactly {num_queries}
[ ] Every query string has zero domain overlap with already_used_search_queries
[ ] search_queries = null if both statuses = FULFILLED
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AGENT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async def shallow_research_prompt(
    research: dict,
    num_queries: int = 2,
) -> ResearchAnalysisOutput:
    try:
        result = await claude_haiku(
            system_prompt=build_system_prompt(num_queries),
            user_prompt=build_user_prompt(research, num_queries),
            user_context=None,
            pydantic_model=ResearchAnalysisOutput,
        )
        return result
    except Exception as e:
        return {"error": f"Error in research analysis: {str(e)}"}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PRINT HELPER
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def print_analysis(output: ResearchAnalysisOutput):
    print("\n" + "=" * 70)
    print("RESEARCH ANALYSIS")
    print("=" * 70)

    print(f"\nğŸ“Š Coverage:")
    print(f"   Primary:   {output.primary_status.value}")
    print(f"   Secondary: {output.secondary_status.value}")

    if output.remaining_primary_research_purpose:
        print(f"\nğŸ”´ REMAINING PRIMARY GAPS ({len(output.remaining_primary_research_purpose)}):")
        for i, gap in enumerate(output.remaining_primary_research_purpose, 1):
            print(f"   {i}. {gap}")

    if output.remaining_secondary_research_purpose:
        print(f"\nğŸŸ¡ REMAINING SECONDARY GAPS ({len(output.remaining_secondary_research_purpose)}):")
        for i, gap in enumerate(output.remaining_secondary_research_purpose, 1):
            print(f"   {i}. {gap}")

    if output.notes:
        print(f"\nğŸ“‹ NOTES  ({len(output.notes)} items):")
        for i, note in enumerate(output.notes, 1):
            src = f"\n     ğŸ”— {note.source}" if note.source else ""
            print(f"\n   {i}. [{note.topic}]\n     {note.description}{src}")

    if output.search_queries:
        print(f"\nğŸ” NEXT SEARCH QUERIES ({len(output.search_queries)} targeting remaining gaps):")
        for i, sq in enumerate(output.search_queries, 1):
            sec = f" / {sq.secondary_identifier}" if sq.secondary_identifier else ""
            print(f"\n   {i}. [{sq.type.upper()}] {sq.name}")
            print(f"      id    : {sq.primary_identifier}{sec}")
            print(f"      query : {sq.query}")

    print("\n" + "=" * 70)
